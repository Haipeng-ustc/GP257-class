{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c83e4556",
   "metadata": {},
   "source": [
    "# Using Dask to process DAS data: \"Seven Trees\" Aftershock (10/25/2022) \n",
    "[//]: <> (Notebook Author: Thomas Cullison, Stanford University, Feb. 2023)\n",
    "\n",
    "\n",
    "In this lab we will be using [Dask](https://docs.dask.org/en/stable/) to accelerate/parallelize the processing of distributed acoustic sensing (DAS) data. In particular, we will be processing data that was recorded during the aftershock of an earthquake that took place near the Seven Trees, CA area in October of 2022.  These data were recorded by a DAS interrogator that was connected to fiber-optic cables that traverse the area around the Stanford campus.\n",
    "\n",
    "\n",
    "## External Resources\n",
    "If you have any question regarding some specific Python functionality you can consult the official [Python documenation](http://docs.python.org/3/).\n",
    "\n",
    "### Dask\n",
    "\n",
    "* [Main Page](https://docs.dask.org/en/stable/)\n",
    "* [General Tutorials \\& Talks](https://docs.dask.org/en/stable/presentations.html)\n",
    "* [Dask-Futures (more specific to this lab)](https://docs.dask.org/en/stable/futures.html)\n",
    "* [Futures Tutorial](https://tutorial.dask.org/05_futures.html)\n",
    "* [Github with Tutorial Jupyter Notebooks](https://github.com/dask/dask-tutorial)\n",
    "* [High-level, but Extensive Overview Tutorial](https://youtu.be/EybGGLbLipI)\n",
    "\n",
    "\n",
    "### DAS\n",
    "\n",
    "* [Distributed Fiber-Optic Sensing](https://youtu.be/LAcQ44YRMuM): Overview of DAS and related technologies\n",
    "\n",
    "\n",
    "## Required Preperation\n",
    "\n",
    "Take a look at the API documentation for the following *dask.distributed* objects and functions.\n",
    "\n",
    "* [Dask-Futures API](https://docs.dask.org/en/stable/futures.html#api)\n",
    "* [Client](https://docs.dask.org/en/stable/futures.html#distributed.Client)\n",
    "* [LocalCluster](https://distributed.dask.org/en/latest/api.html#distributed.LocalCluster)\n",
    "* [Client.map()](https://docs.dask.org/en/stable/futures.html#distributed.Client.map)\n",
    "* [wait()](https://docs.dask.org/en/stable/futures.html#distributed.wait)\n",
    "* [Client.who_has()](https://docs.dask.org/en/stable/futures.html#distributed.Client.who_has)\n",
    "* [Client.gather()](https://docs.dask.org/en/stable/futures.html#distributed.Client.gather)\n",
    "* [Client.cancel()](https://docs.dask.org/en/stable/futures.html#distributed.Client.cancel)\n",
    "* [Client.scatter()](https://docs.dask.org/en/stable/futures.html#distributed.Client.gather)\n",
    "\n",
    "Also, please take a look at the following examples.\n",
    "\n",
    "* [Dask-Futures Examples](https://examples.dask.org/futures.html)\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005e79f",
   "metadata": {},
   "source": [
    "## Exercise 0\n",
    "\n",
    "Please answer the following questions below. (simple answers)\n",
    "\n",
    "1. If one wishes to start a *Local Cluster*, what parameter, if any, needs to be passed to the *Client* constructor?\n",
    "\n",
    "<br>\n",
    "\n",
    "2. What is the difference between the following two *Cluster* parameters: *n_workers* and *threads_per_worker*?\n",
    "\n",
    "<br>\n",
    "\n",
    "3. How can one get a link to the *Dashboard* from a *Client*?\n",
    "\n",
    "<br>\n",
    "\n",
    "4. How can a *LocalCluster* that is associated with a *Client* be rescaled?\n",
    "\n",
    "<br>\n",
    "\n",
    "5. What does the *Client.map()* function return?\n",
    "\n",
    "<br>\n",
    "\n",
    "6. What does the *wait()* function do?\n",
    "\n",
    "<br>\n",
    "\n",
    "7. What does the *Client.who_has()* function do?\n",
    "\n",
    "<br>\n",
    "\n",
    "8. What does the *Client.gather()* function return, and where does the memory exist for the thing or things that are returned (e.g. in the memory of the worker(s), or in the memory of the \"host-python-thread\" (e.g. Jupyter-Notebook thread) that is interacting with the *Client* and *LocalCluster*)?\n",
    "\n",
    "<br>\n",
    "\n",
    "9. Can copies of the same memory exist both in the workers and on the \"host-python-thread\"?\n",
    "\n",
    "<br>\n",
    "\n",
    "10. What function can be used to \"clean-up/release\" the memory held by a worker or workers?\n",
    "\n",
    "<br>\n",
    "\n",
    "11. How can one rescale the number of workers in a cluster?\n",
    "\n",
    "<br>\n",
    "\n",
    "12. How can data that is stored in the \"host-python-thread\" be distributed to workers in a *Cluster*/*LocalCluster*?\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfab826",
   "metadata": {},
   "source": [
    "## Exercise 1: Spin-up Dask-Cluster and Get Raw DAS Data\n",
    "\n",
    "**Tasks for this exercise:**\n",
    "* Import all the python modules that we need\n",
    "* Define the functions we need to get the DAS data from the Cloud and to store the data into *numpy* arrays. \n",
    "* Spin-up a local dask-cluster\n",
    "* Look at the *Dashboard* for the cluster\n",
    "* Pull the data from the Cloud in parallel (one-worker per file)\n",
    "* Collect the data to the \"host-python-thread\" that is running this notebook\n",
    "* Clean-up data that resides in the workers\n",
    "* Rescale the cluster\n",
    "* Concatenate the gathered data along the time-axis to get it ready for parallel proccessing along the time time axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e0fde",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb761d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import datetime\n",
    "import h5py\n",
    "import numba\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import signal\n",
    "from google.cloud import storage\n",
    "from dask.distributed import Client, wait\n",
    "from time import time\n",
    "from os import cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92319cf",
   "metadata": {},
   "source": [
    "### Function Defs for Getting Data from the Cloud\n",
    "\n",
    "These have been defined for you because the knowledge of how to get these data is beyond the scope of this lab. However, it will probably be of some benefit to understand what these functions are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcs_h5_to_buffer(bname,bucket=None):\n",
    "    \"\"\" Pull data from Cloud storage (data is in hdf5 format) \"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket)\n",
    "    blob = bucket.get_blob(bname)\n",
    "    buffer = io.BytesIO()\n",
    "    blob.download_to_file(buffer)\n",
    "    \n",
    "    return buffer\n",
    "\n",
    "\n",
    "def h5_to_array(tbuffer):\n",
    "    \"\"\" Get specific data from hdf5 and store to ndarrays \"\"\"\n",
    "    f = h5py.File(tbuffer, 'r')\n",
    "    data = np.array(f[\"Acquisition\"][\"Raw[0]\"][\"RawData\"],dtype=np.float32)\n",
    "    tata = np.array(f[\"Acquisition\"][\"Raw[0]\"][\"RawDataTime\"],dtype=np.dtype('<i8'))\n",
    "    f.close()\n",
    "    \n",
    "    return data,tata\n",
    "\n",
    "\n",
    "def read_h5_buffer_to_thing(func,bname,bucket=None):\n",
    "    \"\"\" \n",
    "        Interface function for getting hdf5 data from\n",
    "        the cloud and storing it into  different formats\n",
    "    \"\"\"\n",
    "    buffer = gcs_h5_to_buffer(bname,bucket=bucket)\n",
    "    item = func(buffer)\n",
    "    del buffer\n",
    "    return item\n",
    "    \n",
    "    \n",
    "def read_h5_buffer_to_array(bname,bucket=None):\n",
    "    \"\"\" Get ndarrays from the Cloud storage \"\"\"\n",
    "    return read_h5_buffer_to_thing(h5_to_array,bname,bucket=bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8069abaa",
   "metadata": {},
   "source": [
    "### Setup List of Files to Read: (a priori Knowledge Req.)\n",
    "\n",
    "Here we will generate a list of DAS data files that we need to process. Each file stores **one minute's** worth of data, and we will be getting **10** consecutive **minutes** of data for **48,000 channels**. The **channel spacing** is **one meter**. The **time-sampling**, $\\mathbf \\Delta t$, is **0.005 s**, and the aftershock occures within the 10 minute window that we are retrieving.\n",
    "\n",
    "Knowing where this data is stored what files to get is beyond the scope of this lab, but the data is coming from the cloud, and at no point will it be stored to disk, which I think is pretty cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckname = 'das-stanford' #kind of like the head/main directory\n",
    "bdir = 'Stanford-P2kHz-GL20m-FS200Hz-1m-48000_2022-09-29T14_44_55-0700/'\n",
    "\n",
    "\n",
    "lblob_e0 = ['Stanford-P2kHz-GL20m-FS200Hz-1m-48000_2022-10-25T183756Z.h5', \\\n",
    "            'Stanford-P2kHz-GL20m-FS200Hz-1m-48000_2022-10-25T183856Z.h5', \\\n",
    "            'Stanford-P2kHz-GL20m-FS200Hz-1m-48000_2022-10-25T183956Z.h5', \\\n",
    "            'Stanford-P2kHz-GL20m-FS200Hz-1m-48000_2022-10-25T184056Z.h5', \\\n",
    "            'Stanford-P2kHz-GL20m-FS200Hz-1m-48000_2022-10-25T184156Z.h5', \\\n",
    "            'Stanford-P2kHz-GL20m-FS200Hz-1m-48000_2022-10-25T184256Z.h5', \\\n",
    "            'Stanford-P2kHz-GL20m-FS200Hz-1m-48000_2022-10-25T184356Z.h5', \\\n",
    "            'Stanford-P2kHz-GL20m-FS200Hz-1m-48000_2022-10-25T184456Z.h5', \\\n",
    "            'Stanford-P2kHz-GL20m-FS200Hz-1m-48000_2022-10-25T184556Z.h5', \\\n",
    "            'Stanford-P2kHz-GL20m-FS200Hz-1m-48000_2022-10-25T184656Z.h5']\n",
    "\n",
    "bloblist = [bdir+fname for fname in lblob_e0]\n",
    "bucklist = [buckname for fname in lblob_e0]\n",
    "nfiles = len(bloblist)\n",
    "print(f'nfiles: {nfiles}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc92c8",
   "metadata": {},
   "source": [
    "### Start Dask Distributed Cluster: (10 Threads at Most, One-per-file, but Max of ncores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d52ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncore = #use a function call. See imports above\n",
    "nwork = min('?','?') \n",
    "\n",
    "client = Client(n_workers=nwork,processes=True,threads_per_worker=1)\n",
    "#Garbage collection problems if not set ----^   and --------------^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249d5ada",
   "metadata": {},
   "source": [
    "### Show the Dashboard link below\n",
    "\n",
    "Then click the link. It should open another browser tab. Keep this tab open for the duration of this lab. Feel free to explore the *Dashboard*.  One thing of particular interest is the *CPU* tab in the bottom left quadrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0019d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b623daf0",
   "metadata": {},
   "source": [
    "### Show the Memory for Each Worker in the Cluster\n",
    "\n",
    "**Note of Caution:** when each worker has a \"ton\" of different memory chunks, this function can crash a notebook.  It is ok to use it for this exercise, but I *strongly* suggest that you don't use it after this exercise unless it has been explicityly requested to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf74c6c",
   "metadata": {},
   "source": [
    "### Read All Files to Arrays -- Map to Threads : (Memory in Cluster)\n",
    "\n",
    "Take notice of the output. This information can be useful when testing, debugging, or learning, but otherwise it mostly not useful. Read the comments!\n",
    "\n",
    "**Watch** the *Dashboard* after executing the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "arrs = client.map('which-function-goes-here?',bloblist,bucket=buckname,pure=False)\n",
    "# Must set this flag to FALSE ---------------------------------------------^\n",
    "\n",
    "# wait for the workers to finish above\n",
    "wait('what goes here?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77219ba",
   "metadata": {},
   "source": [
    "### Show the Memory for Each Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e823a2",
   "metadata": {},
   "source": [
    "### Gather Arrays to Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc74e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gathered_data = client.gather('what-goes-here?',direct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a6f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show where the memory is (your code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c122b",
   "metadata": {},
   "source": [
    "### Clean-up Cluster Memory\n",
    "\n",
    "Be careful when using cleaning up memory from the workers. The data they store may have a dependency on other data that has yet to be processed. There may also be multiple variables that point to the same data before and after some processing has been applied to the data; therefore, one might accidentaly delete a dependency or unintentionally try to \"double-delete/release\" the same memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf88722",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for t in arrs:\n",
    "    client.cancel('what-goes-here?')\n",
    "client.cancel(arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show where the memory is (your code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b5f7c0",
   "metadata": {},
   "source": [
    "### Scale-down Cluster to One Worker\n",
    "\n",
    "Take a look at the *Dashboard* after you do this, especially the *CPU* tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc10bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a49b1c6",
   "metadata": {},
   "source": [
    "### Concatenate Arrays Over Time Axis: (Notebook Thread)\n",
    "\n",
    "This part has been done for you, but be sure you understand what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd1053",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tup_list = list(map(list, zip(*gathered_data)))\n",
    "rdlist = tup_list[0]\n",
    "rtlist = tup_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea96143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# np.hstack() should also work\n",
    "rdata = np.concatenate(rdlist,axis=1)\n",
    "tdata = np.concatenate(rtlist)\n",
    "\n",
    "# The deletes below are for the \"host-python-thread\" (this notebook), only, \n",
    "# not the workers in the cluster\n",
    "del rdlist[:]\n",
    "del rdlist\n",
    "del rtlist[:]\n",
    "del rtlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b3f2d",
   "metadata": {},
   "source": [
    "## Show the Shape of the Concatenated Array\n",
    "\n",
    "Is it what you expect? if not, you may have to fix something above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574476c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the shape of the concatenated array as a Q.C. (your code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c79a1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "Now that we have collected the data and concatenated it along the time axis, we can preprocess the data so that we can may analyze it. Most of the preprocessign will be done by the workers in our local dask-cluster. However, the last preprocessing step will be done in parallel, using numba, by the \"host-python-thread.\" This last processing step accessed the data at a single-point-in-time but across all channels. Think about why this might be a good idea.\n",
    "\n",
    "**Tasks for this exercise:**\n",
    "* Plot the raw-data via the \"host-python-thread\", so that we can eventually compare with the final preprocessed result.\n",
    "* Define our functions we will used for preproccing.\n",
    "* Scale-up the cluster so that there are as many workers as there are cores\n",
    "* Scatter our concatenated, raw-data, array from the \"host-python-thread\" to the workers (splitting-up along the channel axis, not the time-axis).\n",
    "* Run our preprocessing functions for each channel\n",
    "* Gather the data back to the \"host-python-thread\" for the last preprocessing step.\n",
    "* Shutdown the local dask-cluster\n",
    "* Run the last preprocessing function\n",
    "* Plot the final results of the preprocessing.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e57f3",
   "metadata": {},
   "source": [
    "### Define function for plotting: (host-python-thread only)\n",
    "\n",
    "**Note:** This function has been defined for you. Furthermore, we will only be plotting a subrange of channels because, given the limited screen space of the notebook, it is somewhat cummbersome to look at all 48k channels at once. See the code lines for *start_c* and *end_c*, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dbb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seven_trees_data(data,times,pclip=.95,fig_size=(9,10)):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    eqdate = datetime.datetime.utcfromtimestamp(times[0]//1000000)\n",
    "    start_c = 23000\n",
    "    end_c = 35000 \n",
    "    bounds = (0,nfiles*60,end_c,start_c)\n",
    "\n",
    "\n",
    "    vclip = (1-pclip)*np.abs(data[start_c:end_c+1,:]).max()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.imshow(data[start_c:end_c+1,:], aspect='auto', interpolation='none', cmap='gray', vmin=-vclip, vmax=vclip, extent=bounds)\n",
    "    plt.title('DAS for Seven Trees 1st-Aftershock, 3.1 EQ @' + str(eqdate) )\n",
    "    plt.xlabel('seconds from: ' + str(eqdate.time()))\n",
    "    plt.ylabel('channel')\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558ba9e8",
   "metadata": {},
   "source": [
    "### 2D Plot of the Raw DAS Data\n",
    "\n",
    "This part has been done for you. It will take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f7dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# We will use a different clip after preprocessing because\n",
    "# the dynamic range will be so different\n",
    "pclip = 0. \n",
    "print(f'pclip: {pclip}')\n",
    "\n",
    "plt = plot_seven_trees_data(rdata,tdata,pclip=pclip)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1b6f6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Doesn't the plot above look magnificent!?\n",
    "[//]: <> (as magnificent as Trogdor? https://youtu.be/90X5NJleYJQ)\n",
    "\n",
    "Run the cell below to clean up the memory related to the plot. It can help with making the notebook run more \"smoothly.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc42789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the gunk\n",
    "plt.close('all')\n",
    "del plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015d677e",
   "metadata": {},
   "source": [
    "### Function Defs for Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13693b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that this function will be ran on the \"host-python-thread\"\n",
    "@numba.njit(cache=True, fastmath=True, nogil=True, parallel=True)\n",
    "def remove_median_xchannel(orig_tr):\n",
    "    \"\"\" remove the median cross-channel value for every time sample\"\"\"\n",
    "    rmed_traces = orig_tr.copy()\n",
    "    for it in numba.prange(orig_tr.shape[-1]):\n",
    "        rmed_traces[:, it] -= np.median(orig_tr[:, it])\n",
    "    return rmed_traces\n",
    "\n",
    "\n",
    "def detrend_single_trace(orig_tr):\n",
    "    \"\"\" \n",
    "        Remove the mean and any linear trend in the data along \n",
    "        the time-axis. Runs on the workers.\n",
    "        (operates per channel)\n",
    "    \"\"\"\n",
    "    det_const = signal.detrend(orig_tr,type='constant')\n",
    "    det_trace = signal.detrend(det_const,type='linear')\n",
    "    del det_const\n",
    "    return det_trace\n",
    "\n",
    "\n",
    "def bandpass_butter_single_trace(trace, fs=None, b0=None, bN=None, order=5):\n",
    "    \"\"\" \n",
    "        Band pass the data along the time-axis. Runs on the workers.\n",
    "        (operates per channel)\n",
    "    \"\"\"\n",
    "    sos = signal.butter(order, (b0,bN), 'bandpass', fs=fs, output='sos')\n",
    "    bp_trace = signal.sosfiltfilt(sos, trace)\n",
    "    return bp_trace\n",
    "\n",
    "\n",
    "def silly_decimate_single_trace(orig_tr,q=2):\n",
    "    \"\"\"\n",
    "        Decimate the data after bandpassing. Runs on the Workers. \n",
    "        (operates per channel)\n",
    "    \"\"\"\n",
    "    return orig_tr[::q]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e727cfb2",
   "metadata": {},
   "source": [
    "### Scale-up Cluster to All Cores for Data Processing\n",
    "\n",
    "Look at the *CPU* tab in the *Dashboard* after launching the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f7b625",
   "metadata": {},
   "source": [
    "### Scatter Concatenated, Raw Data to All Workers (from Notebook to Cluster)\n",
    "\n",
    "Read the comments!\n",
    "<br>\n",
    "**Watch** the *Dashboard* as soon as you execute the cell below.\n",
    "<br>\n",
    "**Do NOT** try to display the memory across all the workers. It will likely crash and mangle your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db8a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "future = client.scatter(list('what goes here?'))\n",
    "junk = wait('what goes here?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35859031",
   "metadata": {},
   "source": [
    "### Detrend Data Per Channel: Multiple Channels Per Worker\n",
    "\n",
    "The scheduler decides based on how the data was scattered above.\n",
    "<br>\n",
    "**Watch** the *Dashboard* as soon as you execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87974912",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "det_data = client.map('what-function-goes-here?','what-thing-goes-here?',pure=False)\n",
    "jink = 'what goes here?' \n",
    "\n",
    "rdata_dtype = rdata.dtype #save for gathering\n",
    "del rdata #clean-up Notebook Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc12b3d",
   "metadata": {},
   "source": [
    "### Bandpass Filter Per Channel (Nearly the same as for Detrend)\n",
    "\n",
    "**Watch** the *Dashboard*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44105b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bl = 0.025\n",
    "br = 5.0\n",
    "fs = 200\n",
    "\n",
    "bp_data = client.map('what-function-goes-here?','what-data-goes-here?',fs=fs,b0=bl,bN=br,pure=False)\n",
    "# note how the parameters to the function are passed --------------------^  ---^  ---^\n",
    "junk = 'what goes here?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee115f",
   "metadata": {},
   "source": [
    "### Decimate Per Channel\n",
    "\n",
    "This is slightly faster than if the decimation where done by the \"host-python-thread\" after gathering.\n",
    "<br>\n",
    "**Watch** the *Dashboard*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938a42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "ss = 4 #decimation factor -- same as parameter 'q=' in the function\n",
    "\n",
    "bp_data = client.map('what-function?','what-data?',q='what-goes-here?',pure=False)\n",
    "junk = 'what goes here?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c362aef",
   "metadata": {},
   "source": [
    "### Gather Preprocessed Data: (From cluster to Notebook)\n",
    "\n",
    "It's pretty boring to watch the *Dashboard* for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e349089",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dec_bp_data = np.asarray(client.gather('what-data?',direct=True),dtype=rdata_dtype)\n",
    "#                          ^                       #NOTE: ------------^\n",
    "#                          |\n",
    "# --- LOOK ----------------  # for some reason this is slightly faster than two lines of code\n",
    "\n",
    "\n",
    "# NOTE: np.vstack() has ~same RUNTIME as np.asarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde6656",
   "metadata": {},
   "source": [
    "## Show the Shape of the Processed Array\n",
    "\n",
    "Is it what you expect? if not, you may have to fix something above. Reminder: you have decimated the array along the time-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the shape of the processed array as a Q.C. (your code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c660be",
   "metadata": {},
   "source": [
    "### Release Cluster and Scheduler: (and All Related Resources, i.e. Memory, Cores, etc.)\n",
    "\n",
    "This part has been done for you.\n",
    "<br>\n",
    "Look at the *Dashboard* **after** you run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49473f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "client.shutdown()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c8fa3",
   "metadata": {},
   "source": [
    "### X-Channel Median Removal Per Time-Sample\n",
    "\n",
    "This part has been done for you, and it happens on the \"host-python-thread.\" It will be quite fast compared to the other processing steps. Ponder as to why this is so much faster, and tell me your thoughts on this in the *markdown* cell that follows the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff88068",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "proc_data = remove_median_xchannel('what-goes-here?')\n",
    "\n",
    "del dec_bp_data # clean up notebook memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c6db7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Provide your thoughts on the X-Channel Parallel Speed-up over the Dask-Cluster Processing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19352116",
   "metadata": {},
   "source": [
    "\"Write here\"\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e0ed0",
   "metadata": {},
   "source": [
    "### 2D Plot of the Processed DAS Data (Yay! Finally)\n",
    "\n",
    "This part has been done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a594f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pclip = .99\n",
    "print(f'pclip: {pclip}')\n",
    "\n",
    "plt = plot_seven_trees_data(proc_data,tdata[::ss],pclip=pclip)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a586c31f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Roughly how many seconds into the data does the aftershock arrive?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e3978",
   "metadata": {},
   "source": [
    "\"Write here\"\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1baa1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
