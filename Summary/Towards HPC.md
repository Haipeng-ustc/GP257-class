# Computational Roadmap

Note: This documentation is partly generated by Copilot

This tutorial is based on my experience in computational geophysics. From what I have learned piece by piece, I will try to build a roadmap for computational geophysicists. Hopefully, this tutorial can help you to get started in computational geophysics. I will try to cover the following topics: Programming Environment Setup based on Linux, version management via Git, map the algorithm to the code, code parallelization and optimization, code testing and packaging, reproducibility, etc. 

More specifically, I will cover the prevailing packages in Python, including numpy, and scipy.  For parallel computing involving the usage of OpenMP, MPI and CUDA in Python, I will cover the following packages: dask, numba, mpi4py, multiprocessing, cupy. Also, the logging, argparse, and pytest packages will be covered. For the visualization, I will cover the following packages: matplotlib. 


* TOC
{:toc}


## Lecture-00: Programming Environment Setup
The following contents are based on **Ubuntu 18.04 LTS**. Other Linux distributions may have different commands, and you may find the equivalent commands by yourself. 

Suppose you have a fresh Ubuntu system, then you need to install the following basic packages. 

### 0.1 Installation Basic Packages
```bash 
# install packages including: 
# libc6, libc, gcc, g++, make, dpkg
sudo apt-get install build-essential

# install gfortran, vim, git, etc.
sudo apt install gfortran 
sudo apt install vim
sudo apt install git
sudo apt install screen
sudo apt install htop
sudo apt install wget
```
The above pacakges are necessary for compiling and running C/C++/Fortran programs. These packages are usually installed on the cluster. Please check the installation first before you install them again. For example, you can check the installation of gcc by typing `gcc -v` in the terminal.


### 0.2 Git
[Git](https://git-scm.com/) is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency. [GitHub](https://github.com/) and  [Gitlab](https://about.gitlab.com/) are two popular websites for code hosting, and they are both based on Git. For their differences, please refer to [this article](https://about.gitlab.com/competition/github/). 

This tutorial will use GitHub as an example. In the last step, we have installed git and you can check the installation by typing `git -v` in the terminal. First, we need to create a GitHub accout on the [GitHub website](https://github.com/). Next, we need to configure git locally. Let's add the the ssh key to GitHub. In the terminal, type the following commands. 

```bash
ssh-keygen -t rsa -C “your_Github_email@adrress”
cd ~/.ssh
vim id_rsa.pub
```
Then copy the key into: Your Github website --> Settings --> SSH and GPG keys --> New SSH key. Finally, check the git ssh status by typing `ssh -T`. For a detailed tutorial, please refer to [Generating a new SSH key and adding it to the ssh-agent](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent).


Then, let's configure git. In the terminal, type the following commands. 
```bash
git config --global user.name “your_Github_name”
git config --global user.email “your_Github_email@adrress”
```

Now, we can use git to manage our code. First, we need to create a repository on the GitHub website, and let's name it as `test`. We can clone the new empty remote repository (maybe with only one README.md file in it) to our local computer by typing the following command in the terminal.

```bash
git clone git@github.com:your_Github_name/test.git
```
Then, we can add our code to the local repository cloned from the remote repository. For example, we can create a file named `test.py` in the local repository. Then, we can add the file to the local repository by typing the following command in the terminal.

```bash
# create a file named test.py in the local repository
touch test.py
echo 'print("hello world")' > test.py

# add the file to the local repository and commit the change
git add test.py
git commit -m 'add test.py'
git push
```
Now, we can check the remote repository on the GitHub website. To check the remote repository address of the local repository, we can 
```bash
# check the origin repository address
git remote -v

# if we want to remove the current repository address, we can type
git remote rm origin
```

One of the important file I want to mention is `.gitignore`. This file is used to specify the files that should be ignored by git, such as *big data files*, the compiled files, vscode files, etc. For example, we can create a file named `.gitignore` in the local repository. 
```bash
# create a file named .gitignore in the local repository
touch .gitignore
```
and then add the following contents to the `.gitignore` file.
```bash
## macOS.gitignore
.DS_Store
.AppleDouble
.LSOverride

## VisualStudioCode.gitignore
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
!.vscode/*.code-snippets

## Local History for Visual Studio Code
.history/

# ignore segy, bin, and dat files if any
*.sgy
*.bin
*.dat
```
Finally, we can add the `.gitignore` file to the local repository and commit the change.
```bash
git add .gitignore
git commit -m 'add .gitignore'
git push
```
We can find more `.gitignore` templates on [GitHub](https://github.com/github/gitignore/tree/main/Global). There are many other useful commands for git. For more details, please refer to [Git Handbook](https://guides.github.com/introduction/git-handbook/).
For packaging a project, I will discuss it later including the Readme.md file, the license file, the project structure, etc.

### 0.3 IDE
IDE stands for Integrated Development Environment. It is a software application that provides comprehensive facilities to computer programmers for software development. There are many IDEs for different programming languages. For example, [VSCode](https://code.visualstudio.com/) is a popular IDE for Python, C/C++, Fortran, and almost all the programming languages. [PyCharm](https://www.jetbrains.com/pycharm/) and [Spyder](https://www.spyder-ide.org/) are other popular IDEs for Python, and [Vim](https://www.vim.org/) and [Emacs](https://www.gnu.org/software/emacs/) are popular text editors. In this tutorial, we will use VSCode as the IDE, which is my favorite IDE, which integrates well with *git*, *docker*, *jupyter notebook*, *google could*, and many other prevailing tools. More importantly, it supports *remote development*, which is very useful for using cluster or supercomputer. For more details, please refer to [VSCode Documentation](https://code.visualstudio.com/docs).

We can download the package from the [VSCode website](https://code.visualstudio.com/). Please choose the right version for your system. For Ubuntu 18.04 LTS, we can download the `.deb` package. After downloading the installation package, we can install it by typing the following command in the terminal. 
```bash
sudo dpkg -i code_1.79.2-1686734195_amd64.deb
```
The power of Visual Studio Code comes from the extensions. We can install the extensions by clicking the `Extensions` icon on the left side of the VSCode. We can search the extensions by typing the name of the extensions. I find the following extensions very useful.
- Python
- C/C++
- Fortran
- Remote - SSH
- Remote - Containers
- Jupyter
- Docker
- Markdown
- GitLens — Git supercharged
- Github Copilot
- Google Cloud Code
- etc.

Particularly, the `Remote - SSH` extension is very useful for using remote cluster. For more details, please refer to [Developing on Remote Machines using SSH and Visual Studio Code](https://code.visualstudio.com/docs/remote/ssh) and [Developing in Containers](https://code.visualstudio.com/docs/remote/containers). I would also **STRONGLY** recommend the `Github Copilot` extension, which is a very powerful AI assistant for coding. For more details, please refer to [GitHub Copilot](https://copilot.github.com/).


### 0.4 Anaconda
[Anaconda](https://www.anaconda.com/) is a free and open-source distribution of the Python and R programming languages for scientific computing, that aims to simplify package management and deployment. It is very useful for managing the Python packages. I would also recommend [Miniconda](https://docs.conda.io/en/latest/miniconda.html), which is a smaller version of Anaconda. If you are using Linux, you can download the installation package from the [Miniconda website](https://docs.conda.io/en/latest/miniconda.html). For example, we can download the installation package for Python 3.9 on Linux by typing the following command in the terminal.

```bash
wget https://repo.anaconda.com/miniconda/Miniconda3-py39_4.10.3-Linux-x86_64.sh
```
Then, we can install it by typing the following command in the terminal.
```bash
bash Miniconda3-py39_4.10.3-Linux-x86_64.sh
```
After installing Miniconda, we can create a new environment by typing the following command in the terminal.
```bash
conda create -n seis python=3.9
```
To activate the environment, we can type the following command in the terminal.
```bash
conda activate seis
```
After activating the environment, we can install the Python packages by typing the following command in the terminal.
```bash
pip install numpy scipy matplotlib obspy
```
To deactivate the environment, we can type the following command in the terminal.
```bash
conda deactivate
```
To remove the environment, we can type the following command in the terminal.
```bash
conda remove -n seis --all
```
To delete the environment, we can type the following command in the terminal.
```bash
conda install anaconda-clean
anaconda-clean
```
For more details, please refer to [Managing environments](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html).



### 0.5 Jupyter Notebook
[Jupyter Notebook](https://jupyter.org/) is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. It is very useful for data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, etc. It supports many programming languages, such as Python, C/C++, Fortran, etc. For more details, please refer to [Jupyter Notebook Documentation](https://jupyter-notebook.readthedocs.io/en/stable/). 

One of the popular working modes is to develop the source code in VSCode and then test/run the source code in Jupyter Notebook. We can install the Jupyter Notebook by typing the following command in the terminal.
```bash
pip install jupyter
```

To start the Jupyter Notebook, we can type the following command in the terminal.
```bash
jupyter notebook
```
Then, we can open the Jupyter Notebook in the browser. We can also open and run the Jupyter Notebook in VSCode by clicking the `Open in VSCode` button on the right side of the Jupyter Notebook.

There are many useful magic commands in Jupyter Notebook. The following is an example of using the magic commands in Jupyter Notebook.
```python
# show the figures in the Jupyter Notebook in active mode
%matplotlib inline

# show the figures in the Jupyter Notebook in passive mode
%matplotlib notebook

# reload the modules before executing the Python code
%load_ext autoreload
%autoreload 2

# show the variables in the memory
%whos

# show the time cost of the Python code (repeat multiple times to get the average time cost)
%timeit

# show the time cost of the Python code
%time

# debug the Python code
%debug
```
 For more details, please refer to [IPython Magic Commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html). 


### 0.6 Docker
[Docker](https://www.docker.com/) is a set of platform as a service (PaaS) products that use OS-level virtualization to deliver software in packages called containers. Containers are isolated from one another and bundle their own software, libraries and configuration files; they can communicate with each other through well-defined channels. All containers are run by a single operating system kernel and are thus more lightweight than virtual machines. Containers are created from images that specify their precise contents. Images are often created by combining and modifying standard images downloaded from public repositories. For more details, please refer to [Docker Documentation](https://docs.docker.com/).


### 0.7 Google Cloud
[Google Cloud](https://cloud.google.com/) is a suite of cloud computing services that runs on the same infrastructure that Google uses internally for its end-user products, such as Google Search, Gmail, file storage, and YouTube. For more details, please refer to [Google Cloud Documentation](https://cloud.google.com/docs).



### 0.8 Screen
[Screen](https://www.gnu.org/software/screen/) is a full-screen window manager that multiplexes a physical terminal between several processes, typically interactive shells. It allows us to use multiple shell windows from a single SSH session. It is very useful when we want to run a long-time job on the cluster. For example, we can type the following command in the terminal to create a new screen named `test`.
```bash
screen -S test
```
Then, we can run our program in the new screen. For example, we can run a python program named `test.py` in the new screen.
```bash
python test.py
```
To detach the screen, we can type `Ctrl+a` and then type `d`. To reattach the screen, we can type the following command in the terminal.
```bash
screen -r test
```
To list all the screens, we can type the following command in the terminal.
```bash
screen -ls
```
To kill a screen, we can type the following command in the terminal.
```bash
screen -X -S test quit
```
For more details, please refer to [GNU Screen](https://www.gnu.org/software/screen/).



### 0.9 htop
[htop](https://htop.dev/) is an interactive process viewer for Unix systems. It is very useful for monitoring the system status. For example, we can type the following command in the terminal to monitor the system status.
```bash
htop
```
For more details, please refer to [htop](https://htop.dev/).


### 0.10 wget
[wget](https://www.gnu.org/software/wget/) is a computer program that retrieves content from web servers. It is very useful for downloading files from the Internet. For example, we can type the following command in the terminal to download a file named `Elastic Marmousi` from the Internet.

```bash
# Download the Marmousi2 model
wget https://s3.amazonaws.com/open.source.geoscience/open_data/elastic-marmousi/elastic-marmousi-model.tar.gz
```
For more details, please refer to [GNU Wget](https://www.gnu.org/software/wget/).



## Lecture-01: Scientific Python Programming
There are many programming languages for scientific computing, such as C/C++, Fortran, Python, MATLAB, etc. In this lecture, I will choice Python as the programming language for scientific computing. Python is a high-level, general-purpose, and open-source programming language. It is very popular in scientific computing. It is also very popular in machine learning and deep learning. I will also introduce the basic usage of the Python packages for scientific computing, such as NumPy, SciPy, Matplotlib, ObsPy, etc. Also, I will introduce the programming skills for scientific computing, such as vectorization, parallel computing, object-oriented programming, code optimization, etc. All the following examples are based on the Python 3. 

### 1.1. Python
Since we install the Anaconda, we can use the Python in the Anaconda. We can type the following command in the terminal to start the Python.
```bash
# check the Python distribution
which python

# start the Python
python
```

To learning the Python, I suggest the onlion book [Python Programming And Numerical Methods: A Guide For Engineers And Scientists](https://pythonnumericalmethods.berkeley.edu/notebooks/Index.html). This book is very useful for learning the Python for scientific computing, covering the basic Python, algorithm, data structure, numerical methods, etc.

### 1.2 Python Packages
There are many Python packages for scientific computing, such as NumPy, SciPy, Matplotlib, ObsPy, etc. We can install the Python packages by using the `conda` or `pip`. For example, we can type the following command in the terminal to install the NumPy.
```bash
# install the NumPy
pip install numpy

# specify the version of the NumPy
pip install numpy==1.19.2

# uninstall the NumPy
pip uninstall numpy
```
For seismic data processing and waveform imaging, there are many Python packages, such as ObsPy, Pyrocko, Segyio, etc.



## Lecture-02: From algorithm to code
In my past study and research, I found that it is very to develop the ability of converting the algorithm to code. In this lecture, I will take the full-waveform inversion imaging as an example to introduce the basic skills for converting the algorithm to code. The skills acquired in this lecture are also very useful for other scientific computing. I will also introduce the basic skills for code optimization. 


From what I have learned, the abstraction is very important for scientific computing. The abstraction is the process of removing physical, spatial, or temporal details or attributes in the study of objects or systems in order to more closely attend to other details of interest. For example, we can use the following equation to describe the wave propagation in the elastic medium.



## Lecture-03: Parallel Computing in Python

### 3.1 Parallel Computing
Parallel computing is a type of computation in which many calculations or the execution of processes are carried out simultaneously. Large problems can often be divided into smaller ones, which can then be solved at the same time. There are many parallel computing methods, such as shared memory parallelism, distributed memory parallelism, hybrid parallelism, etc. Some termologies are used to describe the parallel computing, such as process, thread, core, node, etc. For more details, please refer to [Parallel Computing](https://en.wikipedia.org/wiki/Parallel_computing).

Hardware for computing:
| Hardware | Description |
| :---: | :---: |
| Memory | Memory is the faculty of the brain by which data or information is encoded, stored, and retrieved when needed. |
| Cache | A cache is a hardware or software component that stores data so that future requests for that data can be served faster. |
| Disk | A disk is a circular plate or disc that is used to store data, but it is not directly accessible by the CPU and thus slow. |
| CPU | A central processing unit is the electronic circuitry within a computer that executes instructions that make up a computer program. |
| GPU | A graphics processing unit is a specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device. |
| TPU | A tensor processing unit is an AI accelerator application-specific integrated circuit developed by Google specifically for neural network machine learning. |



Table of these termologies:
| Termology | Description |
| :---: | :---: |
| Process | A process is an instance of a computer program that is being executed. |
| Thread | A thread is the smallest sequence of programmed instructions that can be managed independently by a scheduler. |
| Core | A core is a physical processing unit on the CPU. |
| Node | A node is a single machine in a cluster. |
| Cluster | A cluster is a group of computers that work together as a single system. |
| Supercomputer | A supercomputer is a computer with a high level of performance compared to a general-purpose computer. |
| Cloud computing | Cloud computing is the on-demand availability of computer system resources, especially data storage and computing power, without direct active management by the user. |



Types of parallel processing:
| Flynn's taxonomy | Description |
| :---: | :---: |
| SISD | A single instruction operates on a single data element. |
| SIMD | A single instruction operates on multiple data elements. |
| MDSI | Multiple instructions operate on a single data element. |
| MDMI | Multiple instructions operate on multiple data elements. |



### 3.2 Optimize the use of Cache

In Python, the fast axis of the array is the last axis. For example, we can use the following code to create a 2D array. When looping over the array, we should use the fast axis as the inner loop.
```python
import numpy as np

# create a 2D array
a = np.random.rand(1000, 1000)

# loop over the array
for i in range(1000):
    for j in range(1000):
        a[i, j] += 1.0

# bad example! 
for i in range(1000):
    for j in range(1000):
        a[j, i] += 1.0
```
It is worthwhile to note that Fortran and MATLAb uses the column-major order, while C/C++ uses the row-major order. For more details, please refer to [Row-major order](https://en.wikipedia.org/wiki/Row-_and_column-major_order). This distinction should be aware when optimizing the cache performance. 

### 3.3 Vectorization
Vectorization is the process of converting an algorithm from operating on a single value at a time to operating on a set of values at one time. For example, we can use the following code to calculate the sum of two arrays.
```python
import numpy as np

# create two arrays
a = np.random.rand(1000, 1000)
b = np.random.rand(1000, 1000)

# calculate the sum of two arrays by using the loop
c = np.zeros((1000, 1000))
for i in range(1000):
    for j in range(1000):
        c[i, j] = a[i, j] + b[i, j]


# calculate the sum of two arrays by using the vectorization
c = a + b

# or equivalently 
c[:] = a[:] + b[:]
```

### 3.4 Use NumPy Functions
NumPy provides many functions for scientific computing. These functions are implemented by using the C/C++ and Fortran, based on BLAS and LAPACK. For example, we can use the following code to calculate the sum of two arrays.
```python
import numpy as np

# create two arrays
a = np.random.rand(1000, 1000)
b = np.random.rand(1000, 1000)

# calculate the sum of two arrays by using the NumPy function
c = np.add(a, b)
```

NumPy broadcasting is a powerful mechanism that allows NumPy to work with arrays of different shapes when performing arithmetic operations. For example, we can use the following code to calculate the sum of two arrays.
```python
import numpy as np

# create two arrays
a = np.random.rand(1000, 1000)
b = np.random.rand(1000)

# calculate the sum of two arrays by using the NumPy broadcasting
c = a + b
```

### 3.5 Just-in-time Compilation
Just-in-time (JIT) compilation is a way of executing computer code that involves compilation during execution of a program into machine code, siginicantly speeding up the execution time. In other words, the code is compiled on the fly during execution. It should be noted that it takes some time to compile the code when first used, but the execution time can be faster tfor later use. [Numba](https://numba.pydata.org/) is a JIT compiler that is popularly used in Python. It is very easy to use. To install Numba, we can use the following command.
```bash
pip install numba
```

We can use the following code to calculate the sum of two arrays.
```python
import numpy as np
from numba import jit

# define a function
@jit(nopython=True)
def myadd(a, b):
    c = np.zeros((1000, 1000))
    for i in range(1000):
        for j in range(1000):
            c[i, j] = a[i, j] + b[i, j]
    return c

# create two arrays
a = np.random.rand(1000, 1000)
b = np.random.rand(1000, 1000)

# calculate the sum of two arrays by using the function
c = myadd(a, b)
```
The decorator `@jit(nopython=True)` is used to compile the function `myadd` into machine code. The argument `nopython=True` is used to force the function to be compiled into machine code. If the function cannot be compiled into machine code, an error will be raised. For more details, please refer to [Numba](https://numba.readthedocs.io/en/stable/.


### 3.6 Multiprocessing
Python has a global interpreter lock (GIL) that allows only one thread to be executed at a time. This essentially limit the parallelism of Python. However, [Python Multiprocessing](https://docs.python.org/3/library/multiprocessing.html) is a package that supports spawning processes using an API similar to the threading module. It is very easy to use. To install Python Multiprocessing, we can use the following command.
```bash
pip install multiprocessing
```
Please note that there is another package called [multiprocess](https://pypi.org/project/multiprocess/), which is an alternative to the Python standard library `multiprocessing` that uses `dill` instead of `pickle` for serialization. It is also very easy to use. To install multiprocess, we can use the following command.
```bash
pip install multiprocess
```
The following code shows how to use the Python Multiprocessing to print hello world from different processes.
```python
import multiprocessing as mp

def hello_world(isrc):
    print('hello world from process %d' % isrc)

# set up the parameters and arrays
nthreads = 4
nsrc = 10

# calculate traveltimes in parallel
pool = multiprocess.Pool(nthreads)
for i in range(nsrc):
    pool.apply(calcTimes_ishot, args=(isrc, )) # args is a tuple so add comma
pool.close()
pool.join()
```
For more details, please refer to [Python Multiprocessing](https://docs.python.org/3/library/multiprocessing.html) and [multiprocess](https://pypi.org/project/multiprocess/).


### 3.7 GPU Computing
GPU computing is the use of a GPU (graphics processing unit) as a co-processor to accelerate CPUs for general-purpose scientific and engineering computing. [Numba](https://numba.pydata.org/) is a JIT compiler that supports GPU computing. There is an example of using Numba to perform GPU computing.
```python
import numpy as np
from numba import jit, cuda

# define a function for adding two arrays using GPU
@cuda.jit
def myadd_GPU(a, b, c):
    i, j = cuda.grid(2)
    if i < c.shape[0] and j < c.shape[1]:
        c[i, j] = a[i, j] + b[i, j]

# create two arrays
a = np.random.rand(1000, 1000)
b = np.random.rand(1000, 1000)

# calculate the sum of two arrays by using the function
c = np.zeros((1000, 1000))
threadsperblock = (16, 16)
blockspergrid_x = math.ceil(a.shape[0] / threadsperblock[0])
blockspergrid_y = math.ceil(a.shape[1] / threadsperblock[1])
blockspergrid = (blockspergrid_x, blockspergrid_y)
myadd_GPU[blockspergrid, threadsperblock](a, b, c)
```
For more details, please refer to [Numba](https://numba.pydata.org/). Apart from Numba, there are other packages that support GPU computing. For example, we can use [CuPy](https://cupy.dev/) to perform GPU computing. To install CuPy, we can use the following command.
```bash
pip install cupy
```
The following code shows how to use CuPy to calculate the sum of two arrays.
```python
import cupy as cp

# create two arrays
a = cp.random.rand(1000, 1000)
b = cp.random.rand(1000, 1000)

# calculate the sum of two arrays by using the CuPy
c = a + b
```
For more details, please refer to [CuPy](https://cupy.dev/).


### 3.8 Dask
[Dask](https://dask.org/) is a flexible library for parallel computing in Python. It provides advanced parallelism for analytics, enabling performance at scale for the tools you love. Dask is composed of two parts: dynamic task scheduling optimized for computation, and big data collections like parallel arrays, dataframes, and lists that extend common interfaces like NumPy, Pandas, or Python iterators to larger-than-memory or distributed environments. To install Dask, we can use the following command.

```bash
pip install dask
```

The following code shows how to use Dask to calculate the sum of two arrays.
```python
import dask.array as da

# create two arrays
a = da.random.random((1000, 1000), chunks=(100, 100))
b = da.random.random((1000, 1000), chunks=(100, 100))

# calculate the sum of two arrays by using the Dask
c = a + b
```
There are many features of Dask. For more details, please refer to [Dask](https://dask.org/).

### 3.9 MPI4py
[MPI4py](https://mpi4py.readthedocs.io/en/stable/) is a Python package that provides bindings of the Message Passing Interface (MPI) standard for the Python programming language, allowing any Python program to exploit multiple processors on workstations, clusters and supercomputers. To install MPI4py, we can use the following command.

```bash
pip install mpi4py
```
The following code shows how to use MPI4py to print hello world from different processes.
```python
from mpi4py import MPI

comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()

print('hello world from process %d' % rank)
```
In the terminal, we can use the following command to run the Python script.
```bash
mpiexec -n 4 python hello_world.py
```
For more details, please refer to [MPI4py](https://mpi4py.readthedocs.io/en/stable/).



## Lecture-04: Object-Oriented Programming (OOP)
Object-oriented programming (OOP) is a programming paradigm based on the concept of "objects", which can contain data and code: data in the form of fields (often known as attributes or properties), and code, in the form of procedures (often known as methods). A feature of objects is that an object's procedures can access and often modify the data fields of the object with which they are associated (objects have a notion of "this" or "self"). In OOP, computer programs are designed by making them out of objects that interact with one another. OOP languages are diverse, but the most popular ones are class-based, meaning that objects are instances of classes, which also determine their types. Many of the most widely used programming languages (such as C++, Java, Python, etc.) are multi-paradigm and they support object-oriented programming to a greater or lesser degree, typically in combination with imperative, procedural programming. There are many advantages of OOP. For example, OOP helps to reduce the complexity of software development. It also helps to improve the maintainability of software. But it comes with a cost at designing the code. In this lecture, we will learn how to use OOP in Python. There are three main concepts in OOP: **encapsulation**, **inheritance**, and **polymorphism**. We will use the following example to illustrate these concepts.

### 4.1 Public, Protected, and Private Attributes
In Python, there are three types of attributes: public, protected, and private attributes. Public attributes can be accessed by any code in the program. Protected attributes can be accessed by the code in the class and its subclasses. Private attributes can only be accessed by the code in the class. The following code shows how to define public, protected, and private attributes.
```python
class Receiver:
    def __init__(self, name, time):
        self.name = 'geophone'
        self.time = '20230620'
        self._location_x = 0
        self.__component = 'Vz'
```
In the above code, we define a class called `Receiver`. The class has four attributes: `name`, `time`, `_location_x`, and `__component`. The first two attributes are public attributes. The third attribute is a protected attribute. The fourth attribute is a private attribute. To access the attributes of an object, we can use the following code.
```python
receiver = Receiver('geophone', 20)
print(receiver.name)
print(receiver.time)
print(receiver._location_x)
print(receiver.__component)
```
The output of the above code is
```
geophone
20230620
0
AttributeError: 'Receiver' object has no attribute '__component'
```
We can see that we can access the public and protected attributes of an object. But we cannot access the private attributes of an object. To access the private attributes of an object, we can use the following code.
```python
receiver = Receiver('geophone', 20)
print(receiver._Receiver__component)
```
The output of the above code is `Vz`. 

The similar rules also apply to methods. The following code shows how to define public, protected, and private methods. For more details, please refer to [this article](https://www.tutorialsteacher.com/python/public-private-protected-modifiers).


### 4.2 Encapsulation
Encapsulation is the process of combining data and functions into a single unit called class. In other words, encapsulation is the process of hiding the internal details of an object from the outside world. In Python, we can use the keyword `class` to define a class. The following code shows how to define a class called `Receiver`.
```python
class Receiver:
    def __init__(self, location_x, component):
        self.location_x = location_x
        self.component = component

    def printInfo(self):
        print('name: %s, age: %d' % (self.location_x, self.component))
```
In the above code, we define a class called `Receiver`. The class has two attributes: `location_x` and `component`. It also has a method called `printInfo` to print the information of the person. To create an object of the class `Receiver`, we can use the following code to create an object called `receiver`, access the attributes of the object, and call the method of the object.
```python
# create an object of the class Receiver
receiver = Receiver(100.0, 'pressure')

# access the attributes of the object
print(receiver.location_x)
print(receiver.component)

# call the method of the object
receiver.printInfo()
```
In this way, we can use encapsulation to combine data and functions into a single unit called class.

### 4.3 Inheritance
Inheritance is the process of creating a new class from an existing class. The new class is called the derived class, and the existing class is called the base class. The derived class inherits the features of the base class and can have additional features of its own. In Python, we can use the keyword `class` to define a class. The following code shows how to define a derived class called `DASReceiver` from the base class `Receiver`.
```python
class DASReceiver(Receiver):
    """DAS receiver class derived from the base class Receiver"""

    def __init__(self, location_x, component, length):
        # call the constructor of the base class
        super().__init__(location_x, component)

        # add a new attribute
        self.length = length
    

    # override the method of the base class
    def printInfo(self):
        print('location_x: %f, component: %s, length: %f' % (
            self.location_x, self.component, self.length))

    # add a new method
    def printLength(self):
        print('length: %f' % (self.length))
```
The derived class `DASReceiver` inherits the features of the base class `Receiver`. It also has additional features of its own. To create an object of the class `DASReceiver`, we can use the following code to create an object called `das_receiver`, access the attributes of the object, and call the method of the object.
```python
# create an object of the class DASReceiver
das_receiver = DASReceiver(100.0, 'pressure', 1000.0)

# access the attributes of the object
print(das_receiver.location_x)
print(das_receiver.component)
print(das_receiver.length)

# call the method of the object
das_receiver.printInfo()
das_receiver.printLength()
```
In this way, we can use inheritance to create a new class from an existing class.

Sometimes we may want to check whether an object is an instance of a class. We can use the following code to check whether the object `das_receiver` is an instance of the class `DASReceiver`.
```python
print(isinstance(das_receiver, DASReceiver))
```
The output is `True`. It means that the object `das_receiver` is an instance of the class `DASReceiver`.



### 4.4 Polymorphism
Polymorphism is the ability of an object to take on many forms. Polymorphism in Python is achieved by inheritance and method overriding. In Python, we can use the keyword `class` to define a class. The following code shows how to define derived class called `DASReceiver` and `OBNReceiver` from the base class `Receiver`.
```python
class Receiver:
    """Receiver class"""

    def __init__(self, location_x, component):
        self.location_x = location_x
        self.component = component

    def printInfo(self):
        print('location_x: %f, component: %s' % (
            self.location_x, self.component))

# define a derived class called DASReceiver
class DASReceiver(Receiver):
    """DAS receiver class derived from the base class Receiver"""

    def __init__(self, location_x, component, length):
        # call the constructor of the base class
        super().__init__(location_x, component)

        # add a new attribute
        self.length = length
    

    # override the method of the base class
    def printInfo(self):
        print('location_x: %f, component: %s, length: %f' % (
            self.location_x, self.component, self.length))

    # add a new method
    def printLength(self):
        print('length: %f' % (self.length))

# define a derived class called OBNReceiver
class OBNReceiver(Receiver):
    """OBN receiver class derived from the base class Receiver"""

    def __init__(self, location_x, component, orientation):
        # call the constructor of the base class
        super().__init__(location_x, component)

        # add a new attribute
        self.orientation = orientation
    

    # override the method of the base class
    def printInfo(self):
        print('location_x: %f, component: %s, orientation: %f' % (
            self.location_x, self.component, self.orientation))

    # add a new method
    def printOrientation(self):
        print('orientation: %f' % (self.orientation))
```
This feature is called polymorphism. It means that the objects of the derived classes `DASReceiver` and `OBNReceiver` can be used as the objects of the base class `Receiver`. To create an object of the class `DASReceiver`, we can use the following code to create objects called `das_receiver` and `obn_receiver` , access the attributes of the object, and call the method of the object.
```python
# create an object of the class DASReceiver
das_receiver = DASReceiver(100.0, 'pressure', 1000.0)

# create an object of the class OBNReceiver
obn_receiver = OBNReceiver(200.0, 'pressure', 20.0)

# access the attributes of the object
print(das_receiver.printLength)
print(obn_receiver.orientation)
```
This feature allows us to write the basic code for the base class and then use it for the derived classes. It can save us a lot of time and effort. For more information about object-oriented programming, please refer to more resources on the Internet, for example, [Object-Oriented Programming (OOP) in Python 3](https://realpython.com/python3-object-oriented-programming/).



### 4.5 OOP for Seismic Waveform Inversion
In this section, I will use OOP to implement the seismic waveform inversion. Basically, every step is an operator with associated model (m, or input) and data (d, or output). In the abstract sense, the expression can be writen down as follows for linear operator:
$$
d = Fm
$$
where $F$ is the operator. For nonlinear operator, the expression can be writen down as follows:
$$
d = F(m)
$$
To deal with the above operations, we can first abstract the model and data as hypercube. The abstraction level can be as follows:
- vector: multi-dimensional hypercube for containing the model and data
- operator: transform the model to data (forward operator), or transform the data to model (inverse operator, but adjoint operator is more commonly used). The domain of the operator is the model, and the range of the operator is the data. Also, dot-product is defined for the operator for testing the adjointness of the operator.
- solver: solve the inverse problem by minimizing the objective function. The solver can be gradient-based method or non-gradient-based method, thought the gradient-based method is more commonly used.
- problem: the combination of the operator and solver. The problem can be linear or nonlinear. The problem can be formulated as follows:
  - linear problem with the operator $d = Fm$
  - nonlinear problem: with the operator $d = F(m)$
- workflow: the combination of the problems in a workflow.


## Lecture-05: Miscellaneous

### 5.1 Logging
Logging is a very important feature for software development. It can help us to debug the code and track the running process. In Python, we can use the module `logging` to implement the logging feature. There are five log levels in the module `logging`, which are `DEBUG`, `INFO`, `WARNING`, `ERROR`, and `CRITICAL`. The log level `DEBUG` is the lowest level, and the log level `CRITICAL` is the highest level. The log level `WARNING` is the default level. The following code shows how to use the module `logging` to implement the logging feature.
```python
import logging

# create a logger with the name 'my_logger'
logger = logging.getLogger('my_logger')

# set the log level to DEBUG
logger.setLevel(logging.DEBUG)

# create a file handler and set it to write to 'my_log.log'
file_handler = logging.FileHandler('my_log.log')
file_handler.setLevel(logging.DEBUG)

# create a console handler and set it to print messages with level INFO and above
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)

# create a formatter and set it to format the log messages
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)
console_handler.setFormatter(formatter)

# add the handlers to the logger
logger.addHandler(file_handler)
logger.addHandler(console_handler)

# log messages with different levels
logger.debug('This is a debug message')
logger.info('This is an info message')
logger.warning('This is a warning message')
logger.error('This is an error message')
logger.critical('This is a critical message')
```
For more information about the module `logging`, please refer to the [documentation](https://docs.python.org/3/library/logging.html).

### 5.2 Argument Parsing
Argument parsing is a very important feature for software development. It can help us to control the running process of the program. In Python, we can use the module `argparse` to implement the argument parsing feature, which is a way to easily and flexibly handle command line arguments in our Python programs. The following code shows how to use the module `argparse` to implement the argument parsing feature.
```python
import argparse

# create a parser
parser = argparse.ArgumentParser(description='This is a description of the program.')

# add arguments
parser.add_argument('--arg1', type=int, default=1, help='This is the help message for arg1.')
parser.add_argument('--arg2', type=float, default=1.0, help='This is the help message for arg2.')
parser.add_argument('--arg3', type=str, default='1', help='This is the help message for arg3.')

# parse arguments
args = parser.parse_args()

# print arguments or do something else with the arguments
print(args.arg1)
print(args.arg2)
print(args.arg3)
```

### 5.3 Unit Test
The most import thing for software development is to make sure that the code is correct. To do this, we need to test the code. In Python, we can use the module `unittest` to implement the unit test feature. Debugging a complex program is hard. Debugging a complex program that has no unit tests is much harder. The idea behind unit testing is that you write test cases for your code, and when you change something you run the tests. If your changes breaks something that used to work, you know you have done something wrong. The following code shows how to use the module `unittest` to implement the unit test feature.
```python
import unittest

# create a class for unit test
class TestStringMethods(unittest.TestCase):

    # define a method for testing
    def test_upper(self):
        self.assertEqual('foo'.upper(), 'FOO')

    # define a method for testing
    def test_isupper(self):
        self.assertTrue('FOO'.isupper())
        self.assertFalse('Foo'.isupper())

    # define a method for testing
    def test_split(self):
        s = 'hello world'
        self.assertEqual(s.split(), ['hello', 'world'])
        with self.assertRaises(TypeError):
            s.split(2)

# run the unit test
if __name__ == '__main__':
    unittest.main()
```
For more information about the module `unittest`, please refer to the [documentation](https://docs.python.org/3/library/unittest.html).


### 5.4 Packaging and Distribution
Packaging the code is a very important feature for software development. It can help us to distribute the code to other people. One of the popular packaging is through [pyproject.toml](https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/). To make the code installable, we need to create a file named `pyproject.toml` in the root directory of the code. The following code shows how to create a `pyproject.toml` file.
```toml
[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"
```
Before packaging the code, we need to pay attention to the structure of the code. The following is a good structure for the code.
```
code
├── code
│   ├── __init__.py
│   ├── module1.py
│   └── module2.py
├── docs
│   ├── conf.py
│   ├── index.rst
│   └── module1.rst
├── tests
│   ├── __init__.py
│   ├── test_module1.py
│   └── test_module2.py
├── LICENSE
├── pyproject.toml
├── README.md
└── setup.py
```
After packaging the code, we can install the code by running the following command.
```bash
pip install .
```
For more information about packaging the code, please refer to the [documentation](https://packaging.python.org/tutorials/packaging-projects/).

As for the distribution of the code, we can upload the code to [PyPI](https://pypi.org/). We need to pay attention to the following things:
- make sure that the code is runnable
- make sure that the code is installable
- make sure that the code is testable
- make sure that the code is documented
- make sure that the code is versioned
- make sure that the code is licensed
- and so on

## Lecture-06: LLM in accelerated Progromming
The Large Language Model (LLM) is a very important topic in the field of Natural Language Processing (NLP) and has been widely used nowadays. Here, I will introduce the LLM in accelerated programming using [Copilot](https://github.com/features/copilot) and [ChatGPT](https://openai.com/blog/chatgpt). 


### 6.1 Copilot
Copilot is a tool that helps you write better code, by generating code and documentation with a model trained on billions of lines of public code. The following code shows how to use Copilot to generate code. Copilot is seamlessly integrated into VSCode. So, we can use it directly in VSCode. Before using Copilot, we need to install the VSCode extension [GitHub Copilot](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot). Then, we need to have an education account of GitHub. After that, we can use Copilot to generate code for free. In fact, this document is partially generated by Copilot.

### 6.2 ChatGPT
ChatGPT is a very interesting tool that can help us to chat with the computer. We can use it to 
- prototype the code 
- get some ideas for the code
- and so on

But I think it is not a good idea to use it to generate the code directly. Rather, the results generated by ChatGPT can be used as a reference for programming. 





This document is still under development
